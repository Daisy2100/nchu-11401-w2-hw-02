# 對話紀錄 - 房價預測多元線性回歸分析專案

**學號**: 114056036  
**課程**: NCHU 11401 W2 HW02  
**日期**: 2025年10月22日  
**協助工具**: GitHub Copilot

---

## 對話流程摘要

### 1. 專案初始化階段

**使用者需求**:
- 使用 Kaggle 房價資料集進行多元線性回歸分析
- 資料來源：https://www.kaggle.com/datasets/juhibhojani/house-price/discussion?sort=hotness
- 遵循 CRISP-DM 流程
- 需要包含特徵選擇、模型評估、預測區間

**Copilot 回應**:
- 分析資料集基本資訊（187,531筆資料，21個特徵）
- 識別資料集符合作業要求（10-20個特徵）
- 開始建立完整的專案結構

### 2. 資料探索與理解

**技術討論**:
- 資料集過大（>50MB）無法直接讀取，改用Python命令行方式分析
- 發現資料包含數值型和文字型特徵混合
- 目標變數（房價）存在缺失值和異常值
- 多個重要特徵（如面積、設施）以文字形式儲存需要提取

**解決方案**:
- 使用正規表達式從文字中提取數值
- 實施IQR方法處理異常值
- 對類別變數進行Label Encoding

### 3. 程式架構設計

**Copilot 建議的架構**:
1. **模組化設計**: 將CRISP-DM各階段分成獨立函數
2. **雙版本策略**: 基礎版和增強版程式碼
3. **完整文檔**: Jupyter Notebook + Python檔案 + 詳細報告

**實現的功能**:
- 資料清理和預處理函數
- 特徵工程和選擇功能
- 多模型比較（Linear, Ridge, Lasso）
- 完整的視覺化分析

### 4. 特徵工程挑戰

**遇到的問題**:
- 文字特徵需要數值化（如"2 BHK", "1200 sqft"）
- 類別變數過多（如location有數百個不同值）
- 缺失值比例高的特徵處理

**Copilot 解決策略**:
- 使用正規表達式提取數值：`df['col'].str.extract(r'(\d+)')`
- 位置特徵聚類：保留前20個熱門地區，其餘歸為"Other"
- 創建組合特徵：設施總數、面積比例等

### 5. 模型效能優化

**初始結果問題**:
- 基礎版模型R²僅0.15，效能不理想
- 殘差分析顯示存在非線性關係
- 預測區間覆蓋率需要改善

**優化措施**:
- 更嚴格的異常值處理（1%-99%分位數）
- 增加特徵工程深度
- 嘗試正則化方法（Ridge, Lasso）
- 對數轉換實驗

**最終成果**:
- 增強版模型R²提升至0.2025
- 預測區間覆蓋率達94.8%
- 交叉驗證穩定性良好（0.2017±0.0050）

### 6. 視覺化與報告生成

**圖表設計討論**:
- 實際值vs預測值散佈圖
- 殘差分析圖
- 特徵重要性圖
- 預測區間圖
- 模型比較圖

**報告結構**:
- 遵循CRISP-DM完整流程
- 包含技術細節和商業解釋
- 提供實務應用建議
- 標示AI協助內容

---

## 主要技術決策及理由

### 資料預處理策略
```python
# 異常值處理 - 選擇1%-99%分位數而非IQR
price_lower = df['Price (in rupees)'].quantile(0.01)
price_upper = df['Price (in rupees)'].quantile(0.99)
```
**理由**: 房價資料通常有極端值，過於嚴格的異常值處理可能損失重要資訊。

### 特徵選擇方法
```python
# 使用SelectKBest配合F統計量
selector = SelectKBest(score_func=f_regression, k=min(k, X.shape[1]))
```
**理由**: F統計量適合回歸任務，能有效識別與目標變數線性相關的特徵。

### 模型比較策略
```python
models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Lasso Regression': Lasso(alpha=0.1)
}
```
**理由**: 比較基礎線性回歸與正則化方法，選擇最適合資料特性的模型。

---

## 遇到的挑戰與解決方案

### 挑戰1: 資料集檔案過大
**問題**: VS Code無法直接讀取大於50MB的檔案
**解決**: 使用Python命令行工具分批處理和分析資料

### 挑戰2: 混合資料型態
**問題**: 數值資訊以文字形式儲存（如"1200 sqft", "2 BHK"）
**解決**: 正規表達式提取 + 錯誤處理機制

### 挑戰3: 類別變數過多
**問題**: location欄位有數百個不同值，容易造成過擬合
**解決**: 保留前20個熱門地區，其餘歸類為"Other"

### 挑戰4: 模型效能限制
**問題**: 線性回歸假設限制了模型表現
**解決**: 特徵工程創新 + 正則化方法 + 預測區間量化不確定性

---

## AI協助的關鍵貢獻

### 程式碼結構設計
- 提供模組化的函數架構
- 建議完整的錯誤處理機制
- 優化程式碼可讀性和維護性

### 資料科學方法論
- 指導CRISP-DM流程的完整實施
- 建議適當的評估指標選擇
- 提供特徵工程的創意想法

### 視覺化設計
- 設計有意義的圖表組合
- 提供清晰的圖表標題和標籤
- 建議色彩搭配和布局優化

### 技術問題解決
- 協助除錯和錯誤處理
- 提供最佳實踐建議
- 優化演算法效能

---

## 專案成果總結

### 技術成就
- ✅ 完整的資料科學專案流程
- ✅ 雙版本程式碼（基礎版 + 增強版）
- ✅ 模型效能提升（R²從0.15提升至0.20）
- ✅ 完整的預測區間分析
- ✅ 豐富的視覺化圖表

### 文檔品質
- ✅ 詳細的CRISP-DM流程說明
- ✅ 完整的技術報告
- ✅ 清晰的專案說明文件
- ✅ 作業檢查清單

### 程式品質
- ✅ 模組化設計
- ✅ 完整的錯誤處理
- ✅ 詳細的程式碼註釋
- ✅ 可重現的分析結果

---

## 學習收穫

### 技術層面
1. **資料預處理**: 學會處理真實世界的混亂資料
2. **特徵工程**: 從原始資料中創造有價值的特徵
3. **模型評估**: 不僅看準確率，更要重視模型的穩定性和可解釋性
4. **預測區間**: 量化預測的不確定性，提供更完整的資訊

### 方法論層面
1. **CRISP-DM**: 系統性的資料科學專案管理方法
2. **實驗設計**: 比較多種方法，選擇最適合的解決方案
3. **文檔化**: 完整記錄分析過程，確保結果可重現
4. **商業思維**: 將技術結果轉化為商業價值

### 工具使用
1. **GitHub Copilot**: AI協助程式碼開發和問題解決
2. **Python生態系**: pandas, scikit-learn, matplotlib等工具的深度使用
3. **版本控制**: Git管理專案版本和檔案
4. **專案管理**: 清晰的檔案結構和專案組織

---

*此對話紀錄展示了完整的資料科學專案開發過程，從問題定義到解決方案實施，體現了AI工具在現代軟體開發中的重要作用。*